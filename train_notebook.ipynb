{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scan_csv\n",
    "from FastSlidingWindow import *\n",
    "from Util import *\n",
    "from bbd100k_loader import *\n",
    "from scan_csv import progress\n",
    "\n",
    "loader = BBD100K_Loader(True)\n",
    "color_map = generate_color_from_categories(loader.category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "tf.Session(config=config).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(Y_pred, Y):\n",
    "    #print(Y_pred.shape)\n",
    "    zeros = np.zeros([Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1], dtype=np.float32)\n",
    "    y2 = tf.reshape(Y_pred[:, :, :, 2], [Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1])\n",
    "    y4 = tf.reshape(Y_pred[:, :, :, 4], [Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1])\n",
    "    pred_x_w = tf.where(y2 > 0.0, y2, zeros) \n",
    "    pred_x_h = tf.where(y4 > 0.0, y4, zeros) \n",
    "    \n",
    "    x1_t = Y_pred[:, :, :, 1:2] - Y[:, :, :, 2:3] / 2.0\n",
    "    x2_t = Y_pred[:, :, :, 1:2] + Y[:, :, :, 2:3] / 2.0\n",
    "    \n",
    "    y1_t = Y_pred[:, :, :, 3:4] - Y[:, :, :, 4:5] / 2.0\n",
    "    y2_t = Y_pred[:, :, :, 3:4] + Y[:, :, :, 4:5] / 2.0\n",
    "    \n",
    "    x1_p = Y_pred[:, :, :, 1:2] - pred_x_w / 2.0\n",
    "    x2_p = Y_pred[:, :, :, 1:2] + pred_x_w / 2.0\n",
    "    \n",
    "    y1_p = Y_pred[:, :, :, 3:4] - pred_x_h / 2.0\n",
    "    y2_p = Y_pred[:, :, :, 3:4] + pred_x_h / 2.0\n",
    "    \n",
    "    cond1 = x2_t < x1_p\n",
    "    cond2 = x2_p < x1_t\n",
    "    cond3 = y2_t < y1_p\n",
    "    cond4 = y2_p < y1_t\n",
    "    cond_all = tf.logical_or(tf.logical_or(tf.logical_or(cond1, cond2), cond3), cond4)\n",
    "    \n",
    "    ious_np = np.zeros([Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1], dtype=np.float32)\n",
    "    \n",
    "    far_x = tf.where(x2_t < x2_p, x2_t, x2_p)\n",
    "    near_x = tf.where(x1_t > x1_p, x1_t, x1_p)\n",
    "    far_y = tf.where(y2_t < y2_p, y2_t, y2_p)\n",
    "    near_y = tf.where(y1_t > y1_p, y1_t, y1_p)\n",
    "    \n",
    "    inter_area = (far_x - near_x + 1.0) * (far_y - near_y + 1.0)\n",
    "    true_box_area = (x2_t - x1_t + 1.0) * (y2_t - y1_t + 1.0)\n",
    "    pred_box_area = (x2_p - x1_p + 1.0) * (y2_p - y1_p + 1.0)\n",
    "    iou = inter_area / (true_box_area + pred_box_area - inter_area)\n",
    "    iou = tf.where(cond_all, ious_np, iou)\n",
    "    return iou\n",
    "    \n",
    "#iou_1 = calc_iou(Y_pred, Y)\n",
    "#iou = 1.0 - tf.reduce_mean(iou_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_val = 0.1\n",
    "W_M_1 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 3, 32]), dtype=tf.float32, name='WM1')\n",
    "W_M_1_1 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 32, 64]), dtype=tf.float32, name='WM11')\n",
    "W_M_2 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 64, 128]), dtype=tf.float32, name='WM2')\n",
    "W_M_2_1 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 128, 256]), dtype=tf.float32, name='WM21')\n",
    "W_M_2_2 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 256, 256]), dtype=tf.float32, name='WM22')\n",
    "W_M_2_3 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 256, 512]), dtype=tf.float32, name='WM23')\n",
    "W_M_2_4 = tf.Variable(np.random.uniform(-w_val, w_val, [2, 2, 512, 256]), dtype=tf.float32, name='WM24')\n",
    "W_M_3 = tf.Variable(np.random.uniform(-w_val, w_val, [2*2*256, 256]), dtype=tf.float32, name='WM3')\n",
    "W_M_3_1 = tf.Variable(np.random.uniform(-w_val, w_val, [256, 128]), dtype=tf.float32, name='WM31')\n",
    "\n",
    "W_M_C = tf.Variable(np.random.uniform(-w_val, w_val, [128*5, 128]), dtype=tf.float32, name='WMC')\n",
    "\n",
    "W_M_4_F = tf.Variable(np.random.uniform(-w_val, w_val, [128, len(loader.category_dict)*5]), \n",
    "                      dtype=tf.float32, name='WM4F')\n",
    "\n",
    "params = [W_M_1, W_M_1_1, W_M_2, W_M_2_1, W_M_2_2, W_M_2_3, \n",
    "          W_M_2_4, W_M_3, W_M_3_1, W_M_4_F, W_M_C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 must be added for shifted\n",
    "def index_lookup_generator(w, h):\n",
    "    indices = np.zeros([w, h, 5, 2], dtype=np.int32)\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            l = [[i, j-1], [i, j+1], [i, j], [i-1, j], [i+1, j]]\n",
    "            indices[i, j] = l\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(params, extention=''):\n",
    "    for p in params:\n",
    "        np.save(\"weights/\"+p.name.replace(':', '_')+'_'+extention, p.numpy())\n",
    "        \n",
    "def load_weights(params, extention=''):\n",
    "    for p in params:\n",
    "        p.assign(np.load(\"weights/\"+p.name.replace(':', '_')+'_'+extention+'.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X):\n",
    "    X_flat = tf.reshape(X, [X.shape[0]*X.shape[1], X.shape[2], X.shape[3], X.shape[4]])\n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(X_flat, W_M_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(encode_conv, W_M_1_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = encode_conv\n",
    "\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_3, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_4, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    #print(share_conv.shape)\n",
    "    \n",
    "    share_flat = tf.reshape(share_conv, [share_conv.shape[0], W_M_3.shape[0]])\n",
    "    flat_1 = tf.nn.leaky_relu(tf.matmul(share_flat, W_M_3), alpha=0.1)\n",
    "    flat_2 = tf.nn.leaky_relu(tf.matmul(flat_1, W_M_3_1), alpha=0.1)\n",
    "        \n",
    "    flat_2 = tf.reshape(flat_2, [X.shape[0], X.shape[1], flat_2.shape[1]])\n",
    "    padded = tf.pad(flat_2, [[1, 1], [1, 1], [0, 0]])\n",
    "    indices = index_lookup_generator(X.shape[0], X.shape[1]) + 1\n",
    "    collaborations = tf.gather_nd(padded, indices)\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "    final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    for i in range(2):\n",
    "        final = tf.reshape(final, [X.shape[0], X.shape[1], final.shape[1]])\n",
    "        padded = tf.pad(final, [[1, 1], [1, 1], [0, 0]])\n",
    "        collaborations = tf.gather_nd(padded, indices)\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "        final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    Y_pred = tf.matmul(final, W_M_4_F)\n",
    "    Y_pred = tf.reshape(Y_pred, [Y_pred.shape[0], len(loader.category_dict), 5])\n",
    "    Y_pred = tf.reshape(Y_pred, Y.shape)\n",
    "    \n",
    "    class_pred = tf.nn.sigmoid(Y_pred[:, :, :, 0])\n",
    "    xc_pred = Y_pred[:, :, :, 1]\n",
    "    yc_pred = Y_pred[:, :, :, 3]\n",
    "    xw_pred = tf.square(Y_pred[:, :, :, 2])\n",
    "    yw_pred = tf.square(Y_pred[:, :, :, 4])\n",
    "    \n",
    "    #Y_pred = tf.nn.leaky_relu(Y_pred, alpha=0.5)\n",
    "    Y_pred = tf.stack([class_pred, \n",
    "                       xc_pred, \n",
    "                       xw_pred, \n",
    "                       yc_pred, \n",
    "                       yw_pred], axis=3)\n",
    "\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared(inputs, targets):\n",
    "    error = tf.to_double(inputs) - tf.to_double(targets)\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def bbox_loss(Y_pred, Y):\n",
    "    ms = mean_squared(Y_pred[:, :, 0], Y[:, :, 0])\n",
    "    xm = mean_squared(Y_pred[:, :, 1], Y[:, :, 1])\n",
    "    ym = mean_squared(Y_pred[:, :, 3], Y[:, :, 3])\n",
    "    xwm = mean_squared(Y_pred[:, :, 2], Y[:, :, 2])\n",
    "    ywm = mean_squared(Y_pred[:, :, 4], Y[:, :, 4])\n",
    "    return ms+xm+ym+xwm+ywm\n",
    "\n",
    "def back_prop(X, Y):\n",
    "    y_m = np.mean(Y[:, :, :, 0], axis=2) >= 0.0\n",
    "    Y_true = Y[y_m]\n",
    "    X_flat = X[y_m]\n",
    "    \n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(X_flat, W_M_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(encode_conv, W_M_1_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = encode_conv\n",
    "\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_3, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_4, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    #print(share_conv.shape)\n",
    "    \n",
    "    share_flat = tf.reshape(share_conv, [share_conv.shape[0], W_M_3.shape[0]])\n",
    "    flat_1 = tf.nn.leaky_relu(tf.matmul(share_flat, W_M_3), alpha=0.1)\n",
    "    flat_2 = tf.nn.leaky_relu(tf.matmul(flat_1, W_M_3_1), alpha=0.1)\n",
    "        \n",
    "    flat_2 = tf.reshape(flat_2, [X.shape[0], X.shape[1], flat_2.shape[1]])\n",
    "    padded = tf.pad(flat_2, [[1, 1], [1, 1], [0, 0]])\n",
    "    indices = index_lookup_generator(X.shape[0], X.shape[1]) + 1\n",
    "    collaborations = tf.gather_nd(padded, indices)\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "    final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    for i in range(2):\n",
    "        final = tf.reshape(final, [X.shape[0], X.shape[1], final.shape[1]])\n",
    "        padded = tf.pad(final, [[1, 1], [1, 1], [0, 0]])\n",
    "        collaborations = tf.gather_nd(padded, indices)\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "        final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    Y_pred = tf.matmul(final, W_M_4_F)\n",
    "    Y_pred = tf.reshape(Y_pred, [Y_pred.shape[0], len(loader.category_dict), 5])\n",
    "    \n",
    "    class_pred = tf.nn.sigmoid(Y_pred[:, :, 0])\n",
    "    xc_pred = Y_pred[:, :, 1]\n",
    "    yc_pred = Y_pred[:, :, 3]\n",
    "    xw_pred = tf.square(Y_pred[:, :, 2])\n",
    "    yw_pred = tf.square(Y_pred[:, :, 4])\n",
    "    \n",
    "    #Y_pred = tf.nn.leaky_relu(Y_pred, alpha=0.5)\n",
    "    Y_pred = tf.stack([class_pred, \n",
    "                       xc_pred, \n",
    "                       xw_pred, \n",
    "                       yc_pred, \n",
    "                       yw_pred], axis=2)\n",
    "    \n",
    "    loss_value = bbox_loss(Y_pred, Y_true)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "loss_values = []\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_list = []\n",
    "loss_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============================---------] 77.1% -> 53853\r"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "def plot_loss(losses):\n",
    "    losses_np = np.array(losses)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(losses_np, label='loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "patch_size = 150\n",
    "stride = 50\n",
    "\n",
    "loss = 0.0\n",
    "\n",
    "while True:\n",
    "    X, Y, image, cmap = loader.gather(index, stride, patch_size, 0.1)\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    \n",
    "    if image is not None:\n",
    "        if np.max([image.shape[0], image.shape[1]]) >= 2000:\n",
    "            image = None\n",
    "\n",
    "    if image is not None:\n",
    "        iou_sum = 0.0\n",
    "        iou_mean = 0.0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = back_prop(X, Y)\n",
    "\n",
    "        loss += loss_value.numpy()\n",
    "        if loss_value.numpy() < 0.0:\n",
    "            print('dun goofd')\n",
    "            break\n",
    "            \n",
    "        grads_and_vars = tape.gradient(loss_value, params)\n",
    "        capped_grads_and_vars = [tf.clip_by_value(gv, -5., 5.) for gv in grads_and_vars]\n",
    "        optimizer.apply_gradients(zip(capped_grads_and_vars, params), \n",
    "                                              global_step=tf.train.get_or_create_global_step()) \n",
    "        \n",
    "        Y_pred = feed_forward(X)\n",
    "        #Y_pred_list.append(Y_pred)\n",
    "        img_orig = draw_from_label(image, Y, cmap, patch_size, color_map, 0.1, draw_patches=False, \n",
    "                                   max_count=1000)\n",
    "        img_pred = draw_from_label(image, Y_pred.numpy(), cmap, patch_size, color_map, 0.9, \n",
    "                                   max_count=100, draw_patches=False)\n",
    "\n",
    "        cv2.imshow('orig', img_orig)\n",
    "        cv2.imshow('pred', img_pred)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    progress(index, loader.image_count, index)\n",
    "    index += 1\n",
    "    if index % 100 == 0:\n",
    "        save_weights(params, extention='bckp')\n",
    "    if index >= loader.image_count:\n",
    "        index = 0\n",
    "        loss_values.append(loss)\n",
    "        plot_loss(loss_values)\n",
    "        print(' ' + str(loss))\n",
    "        loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, image, cmap = loader.gather(333, stride, patch_size, 0.1)\n",
    "X = np.array(X, dtype=np.float32)\n",
    "Y_pred = feed_forward(X)\n",
    "while(True):\n",
    "    img_orig = draw_from_label(image, Y, cmap, patch_size, color_map, 0.1, draw_patches=False, max_count=1000)\n",
    "    img_pred = draw_from_label(image, Y_pred.numpy(), cmap, patch_size, color_map, 0.0, draw_patches=True)\n",
    "    cv2.imshow('orig', img_orig)\n",
    "    cv2.imshow('pred', img_pred)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    X, Y, image, cmap = loader.gather(333, stride, patch_size, 0.1)\n",
    "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, 60.0, (image.shape[1], image.shape[0]))\n",
    "    last_Y_pred = None\n",
    "    for Y_pred in Y_pred_list:\n",
    "        img_pred = draw_from_label(image, Y_pred.numpy(), cmap, \n",
    "                                   patch_size, color_map, 0.1, draw_patches=False, max_count=10000)\n",
    "        out.write(img_pred)\n",
    "        last_Y_pred = Y_pred\n",
    "\n",
    "    for i in range(120):\n",
    "        img_pred = draw_from_label(image, last_Y_pred.numpy(), cmap, \n",
    "                                   patch_size, color_map, 0.5, draw_patches=False, max_count=10000)\n",
    "        out.write(img_pred)\n",
    "        \n",
    "    for i in range(120):\n",
    "        img_pred = draw_from_label(image, last_Y_pred.numpy(), cmap, \n",
    "                                   patch_size, color_map, 0.7, draw_patches=False, max_count=10000)\n",
    "        out.write(img_pred)\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.05208798, -0.07406985,  0.03429108,  0.02204066,\n",
       "           0.02039959, -0.04935659, -0.08858165, -0.04712377,\n",
       "          -0.02335861,  0.03216594,  0.01607963, -0.08211844,\n",
       "           0.08094801, -0.05007463, -0.00163836,  0.07918039,\n",
       "          -0.02829306, -0.03081325,  0.06471279, -0.06322054,\n",
       "           0.03606274,  0.03993237,  0.08019362, -0.06581432,\n",
       "           0.09527073, -0.07707809, -0.01884496, -0.0148764 ,\n",
       "          -0.08801172, -0.02484374,  0.05043814,  0.05194013],\n",
       "         [-0.00989616, -0.02938471, -0.01979297,  0.04108948,\n",
       "           0.00213967,  0.05592514, -0.07352982,  0.06075403,\n",
       "          -0.05287595,  0.07982644,  0.08964816, -0.07664981,\n",
       "           0.05745313,  0.06754421,  0.09812654,  0.05361671,\n",
       "          -0.06780492, -0.06238389, -0.06062884, -0.01515628,\n",
       "           0.09343061, -0.02520718,  0.00342331,  0.00062984,\n",
       "           0.03969137, -0.0855668 ,  0.0283854 ,  0.02601721,\n",
       "           0.06839868,  0.04293769,  0.02970318,  0.01174047],\n",
       "         [-0.02539871, -0.02487096,  0.08579583, -0.04938631,\n",
       "           0.03576928, -0.04069428,  0.07286538, -0.04230593,\n",
       "           0.01487562, -0.04395526,  0.03322495, -0.0600349 ,\n",
       "           0.02800647,  0.00705331,  0.04127752, -0.09093947,\n",
       "           0.00599306,  0.07322054, -0.05016535, -0.01193735,\n",
       "           0.06210174,  0.07707068, -0.09569618, -0.03632682,\n",
       "           0.09743271, -0.05874185, -0.08983526,  0.01713104,\n",
       "           0.09003365, -0.06372077,  0.06155952, -0.07143577]],\n",
       "\n",
       "        [[-0.02296199,  0.09555594, -0.01765709, -0.00925958,\n",
       "           0.01374803, -0.04357589,  0.02345496, -0.01462577,\n",
       "           0.0696682 ,  0.09744737, -0.06434973,  0.0374269 ,\n",
       "          -0.08281631, -0.06708292, -0.00704304, -0.06324185,\n",
       "           0.0757639 , -0.04347917,  0.00286066, -0.08695712,\n",
       "           0.06515114,  0.07398712,  0.06578339,  0.02287659,\n",
       "          -0.00487723,  0.04108199, -0.07416802, -0.09419935,\n",
       "           0.05701076, -0.0494928 ,  0.04385076, -0.02808163],\n",
       "         [-0.02003251, -0.08228864,  0.01092681, -0.03223822,\n",
       "          -0.06067837,  0.10065909,  0.05705782,  0.01375087,\n",
       "          -0.00692833,  0.05074077,  0.0593235 , -0.01886551,\n",
       "           0.04082407, -0.02377114, -0.07005307,  0.06087678,\n",
       "           0.07440729,  0.0153698 ,  0.0754016 , -0.0542967 ,\n",
       "           0.02905947, -0.0977178 ,  0.04061935,  0.06424919,\n",
       "          -0.01753809, -0.02113258,  0.02867545, -0.0154704 ,\n",
       "           0.01471688, -0.06875867, -0.0979262 ,  0.08561371],\n",
       "         [ 0.06564528,  0.05209937, -0.07243684, -0.02318215,\n",
       "          -0.04879175,  0.05177211,  0.03494291,  0.00335644,\n",
       "          -0.05754422,  0.00048651, -0.07783755, -0.05917939,\n",
       "          -0.04183064, -0.06308938,  0.06087016, -0.00566912,\n",
       "           0.08166   ,  0.05053624, -0.05542862,  0.04608444,\n",
       "          -0.03555008,  0.05614062,  0.09752982, -0.06064583,\n",
       "           0.09835154,  0.09050492,  0.01146908,  0.02279184,\n",
       "          -0.04146264, -0.04125006, -0.08230267, -0.06885461]],\n",
       "\n",
       "        [[ 0.03040017, -0.09088716, -0.01739692, -0.06803798,\n",
       "           0.09752766, -0.04904655,  0.00623988,  0.07975653,\n",
       "          -0.01069296, -0.00968518,  0.02865834, -0.06228338,\n",
       "           0.02525455,  0.0926109 , -0.08728361, -0.00872135,\n",
       "           0.07189814,  0.05129831,  0.06584293, -0.02859958,\n",
       "          -0.04283224, -0.01851186,  0.05544139,  0.02163155,\n",
       "          -0.0626415 , -0.00272657, -0.09791271,  0.00385999,\n",
       "           0.01357356,  0.01104853, -0.03434459,  0.03328322],\n",
       "         [-0.02416912,  0.0459221 , -0.02396058, -0.06003851,\n",
       "          -0.01870976,  0.05772584,  0.0407372 ,  0.03216497,\n",
       "           0.05469536,  0.01919896, -0.07191866, -0.01420673,\n",
       "           0.06127907,  0.07685275,  0.01179074,  0.05075863,\n",
       "          -0.09853522, -0.0176658 , -0.03622597, -0.00973393,\n",
       "          -0.07799497, -0.03851334,  0.03823437,  0.00973846,\n",
       "           0.0008846 ,  0.09917329,  0.06483238,  0.01839344,\n",
       "           0.0532316 ,  0.04304207, -0.003569  ,  0.01249816],\n",
       "         [-0.07564758, -0.00184689,  0.07289008, -0.02560383,\n",
       "           0.04295116, -0.07589278, -0.05001908,  0.09825774,\n",
       "           0.05738967, -0.08501818, -0.08486985,  0.00563905,\n",
       "           0.05519649, -0.03332216,  0.01559075,  0.07862003,\n",
       "          -0.01020365,  0.0410956 , -0.06083005,  0.0048723 ,\n",
       "           0.07873543,  0.03353244,  0.04463891, -0.09137767,\n",
       "           0.05647355,  0.04347872,  0.05757022,  0.02670923,\n",
       "          -0.05147434, -0.01986479,  0.03638021,  0.07029286]]],\n",
       "\n",
       "\n",
       "       [[[-0.06198235,  0.02292415, -0.059976  , -0.05327199,\n",
       "          -0.02015585, -0.01447407,  0.09016094,  0.10287856,\n",
       "          -0.03220945,  0.0042408 , -0.07322611,  0.08936029,\n",
       "           0.09272879, -0.04374958, -0.06296745, -0.08106972,\n",
       "          -0.09295403, -0.01390974, -0.07976419,  0.00926406,\n",
       "           0.07714398,  0.0123637 ,  0.02376151, -0.08287194,\n",
       "          -0.09637139, -0.08212391, -0.02750034, -0.02581875,\n",
       "          -0.06180966, -0.03374112, -0.07228376, -0.03800821],\n",
       "         [-0.02232201,  0.0999685 , -0.07957904, -0.03772323,\n",
       "          -0.04481277, -0.08533886,  0.02952295, -0.08368468,\n",
       "           0.10041808,  0.00333449,  0.05103718,  0.01764788,\n",
       "           0.07273314,  0.0436594 ,  0.09266464,  0.0618466 ,\n",
       "          -0.05314783,  0.00808401, -0.00548764,  0.0677793 ,\n",
       "          -0.02563013,  0.02216607, -0.00612275, -0.07877722,\n",
       "           0.03038402,  0.06538718,  0.00761332, -0.01179875,\n",
       "           0.02327119,  0.10690124, -0.00268059, -0.07724006],\n",
       "         [-0.02670966, -0.04043356, -0.01430894,  0.0598482 ,\n",
       "          -0.07625942,  0.00746425,  0.01805549, -0.00268595,\n",
       "           0.04981877, -0.01369679, -0.09853178, -0.04452375,\n",
       "           0.0770155 , -0.05343304,  0.07392938,  0.00796891,\n",
       "          -0.07020532,  0.07658796,  0.06453728, -0.01988011,\n",
       "           0.06499428,  0.0877561 ,  0.04353255,  0.09269747,\n",
       "           0.06266545, -0.09063502, -0.07602189, -0.03963881,\n",
       "          -0.03858379,  0.01856677, -0.06244518,  0.00912806]],\n",
       "\n",
       "        [[-0.0069352 ,  0.06249118,  0.00125825,  0.04370489,\n",
       "           0.0651034 ,  0.00637435,  0.09632338,  0.04499513,\n",
       "           0.07755842,  0.01417922, -0.02621139,  0.05176415,\n",
       "          -0.01173485,  0.09179821, -0.0434627 ,  0.02259995,\n",
       "           0.03944983,  0.03629079,  0.06167754,  0.03922266,\n",
       "          -0.01792116,  0.01342243,  0.08247854, -0.03544265,\n",
       "           0.08823925, -0.02014775, -0.00646411,  0.04598132,\n",
       "          -0.04227232,  0.035004  , -0.08118464, -0.09235118],\n",
       "         [-0.02214779, -0.08304904,  0.05002977,  0.03419838,\n",
       "           0.05688661,  0.0038432 , -0.06733432,  0.05895472,\n",
       "           0.05451738, -0.00922168, -0.05298977, -0.00521581,\n",
       "           0.08007839, -0.098186  , -0.03053137,  0.08122668,\n",
       "           0.06987253, -0.00889215, -0.01574053, -0.06071984,\n",
       "           0.00106685, -0.04869196,  0.03972642, -0.00639438,\n",
       "          -0.09245317,  0.08739118, -0.05636396, -0.08522039,\n",
       "           0.09497995,  0.06893682, -0.02893014, -0.04396307],\n",
       "         [-0.02998375,  0.05264289,  0.02736962,  0.00508748,\n",
       "          -0.04730086, -0.0678371 , -0.02596194, -0.03218575,\n",
       "           0.00884162, -0.0032985 ,  0.00481124, -0.04806602,\n",
       "          -0.0591317 ,  0.01980596, -0.07192308,  0.08554694,\n",
       "           0.06258321,  0.01669748, -0.05350265, -0.03166951,\n",
       "          -0.02330037,  0.0481909 , -0.00357639,  0.01852946,\n",
       "          -0.06365404, -0.09021434,  0.07581906,  0.02618013,\n",
       "           0.0915162 , -0.07319817, -0.05767555,  0.02811104]],\n",
       "\n",
       "        [[ 0.00254711,  0.0510393 ,  0.03785686, -0.01784142,\n",
       "           0.03390852,  0.07271164,  0.08188578,  0.05304868,\n",
       "          -0.05281951,  0.09574908, -0.00155972, -0.01024332,\n",
       "           0.06488018, -0.10012072,  0.0020138 ,  0.07085826,\n",
       "          -0.09252641, -0.05113335,  0.03884623,  0.00540979,\n",
       "           0.07146047,  0.06606437,  0.08818609, -0.0033902 ,\n",
       "          -0.05210712,  0.07737403, -0.05941941,  0.04726012,\n",
       "           0.09397621, -0.05239947, -0.07516728,  0.0600355 ],\n",
       "         [-0.04164008, -0.04000357,  0.0151997 , -0.02743092,\n",
       "          -0.08369657,  0.01324462,  0.00213443, -0.00053136,\n",
       "          -0.03963446,  0.04435167, -0.03557365,  0.03024172,\n",
       "          -0.07875869, -0.00737072,  0.0530667 ,  0.06954248,\n",
       "          -0.05505419, -0.04129839, -0.09310159, -0.08024902,\n",
       "           0.04815787,  0.00189179,  0.09987503, -0.04214946,\n",
       "          -0.02158025, -0.04420865,  0.07022415,  0.08377958,\n",
       "          -0.05291185,  0.09225264,  0.07846528, -0.01797864],\n",
       "         [-0.05290366, -0.05184267,  0.09998266, -0.07315157,\n",
       "          -0.03340348, -0.08742393,  0.09296966,  0.06958781,\n",
       "           0.04508766, -0.01015294, -0.00328998,  0.09381429,\n",
       "          -0.07338326, -0.03882904, -0.07567248, -0.01172083,\n",
       "          -0.03494875,  0.04768607,  0.04162113,  0.05214563,\n",
       "           0.0277948 , -0.00249463,  0.04544651,  0.04537274,\n",
       "           0.09467888, -0.0308996 , -0.09058945, -0.04890117,\n",
       "           0.03709062, -0.06104361,  0.00019104, -0.09196848]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00274483,  0.03267864,  0.06043952, -0.03789598,\n",
       "           0.0535708 ,  0.0440594 ,  0.06566121,  0.0342348 ,\n",
       "           0.04169861,  0.06292586,  0.0444905 ,  0.07712649,\n",
       "           0.07755477, -0.09303018, -0.0974822 , -0.08416221,\n",
       "          -0.0521639 ,  0.04948146, -0.0935212 , -0.0929648 ,\n",
       "          -0.09700122,  0.09821547, -0.02853896, -0.01308974,\n",
       "           0.07951418,  0.04040861,  0.09706242,  0.02196716,\n",
       "          -0.08219213,  0.00223581, -0.04734202, -0.07610986],\n",
       "         [-0.04811634, -0.0003357 , -0.02554606, -0.02851686,\n",
       "           0.06934788, -0.03653519,  0.00244568,  0.0870747 ,\n",
       "           0.04666727,  0.02474905, -0.09551945, -0.05460104,\n",
       "           0.04091906,  0.05069901,  0.06412388,  0.028209  ,\n",
       "          -0.07756917, -0.03244482, -0.03453602, -0.0892164 ,\n",
       "           0.03228952,  0.00949531, -0.05453538, -0.04927868,\n",
       "          -0.05022463,  0.09691302,  0.095467  , -0.0924186 ,\n",
       "           0.04629365, -0.05391917,  0.09968835,  0.00914126],\n",
       "         [ 0.00745865, -0.08599625,  0.09563684,  0.01876321,\n",
       "          -0.04202342, -0.08823141, -0.08325439,  0.0117022 ,\n",
       "           0.05950886, -0.07475305,  0.0357544 , -0.05011665,\n",
       "          -0.08635567,  0.00797994, -0.02513912,  0.01611315,\n",
       "          -0.02473741, -0.04932032,  0.08069933,  0.0151818 ,\n",
       "          -0.08590643,  0.10137159,  0.07192145,  0.06722645,\n",
       "           0.00059083,  0.06782989, -0.08497455, -0.00155551,\n",
       "          -0.06739068, -0.05937735,  0.09693617, -0.0174389 ]],\n",
       "\n",
       "        [[ 0.09049208, -0.05350045, -0.00847743, -0.07092384,\n",
       "           0.04133721,  0.06862698,  0.04704118,  0.03459565,\n",
       "          -0.07380354, -0.08495317, -0.02477425, -0.05946877,\n",
       "          -0.05427375, -0.03359854,  0.00630942, -0.04778169,\n",
       "           0.02300965,  0.08240495, -0.06825852,  0.05614528,\n",
       "          -0.0238133 ,  0.08677807,  0.10210697,  0.04577148,\n",
       "          -0.05875698, -0.03421313, -0.07004936, -0.09153901,\n",
       "           0.07527237,  0.06188655,  0.04053681,  0.0377752 ],\n",
       "         [-0.09431032,  0.06469702, -0.08318271,  0.02153773,\n",
       "          -0.09013635,  0.09240097,  0.07886931, -0.01744658,\n",
       "          -0.00396381,  0.03190655,  0.00751987, -0.03061748,\n",
       "           0.02573656,  0.07042047,  0.06613141, -0.00453167,\n",
       "           0.00049135,  0.03004788,  0.01215196, -0.00055824,\n",
       "          -0.03944295,  0.0318469 , -0.08488461,  0.02697626,\n",
       "           0.0042254 ,  0.00168698, -0.04340127, -0.06968489,\n",
       "           0.05660801, -0.00094824,  0.06577685, -0.06211566],\n",
       "         [ 0.0141446 , -0.01723687, -0.04853097, -0.05442415,\n",
       "           0.01100927, -0.00123219, -0.08513837,  0.07782789,\n",
       "           0.09012157,  0.06800695, -0.02230169,  0.03981825,\n",
       "           0.02540031,  0.06346066,  0.10109092,  0.08365083,\n",
       "          -0.01929771,  0.02808329,  0.0451775 , -0.03639023,\n",
       "          -0.00277082, -0.02244311, -0.0242113 ,  0.08291524,\n",
       "           0.04313316,  0.10538716, -0.04135665, -0.06355522,\n",
       "           0.08536288, -0.09703241,  0.04804393, -0.0785341 ]],\n",
       "\n",
       "        [[ 0.07258572, -0.04827768,  0.03018712, -0.05418766,\n",
       "          -0.07944737,  0.07752606,  0.02237023, -0.0365985 ,\n",
       "           0.07049023, -0.05663733, -0.06793185, -0.081218  ,\n",
       "          -0.01357795, -0.01470457, -0.01242114, -0.09477913,\n",
       "          -0.06561937, -0.01555052,  0.02484847,  0.05755931,\n",
       "          -0.00497951,  0.08027118,  0.02216201,  0.09856027,\n",
       "          -0.03620626,  0.07871345, -0.0323318 , -0.07395674,\n",
       "          -0.09544021, -0.06452617,  0.03539024,  0.01448035],\n",
       "         [ 0.00286506, -0.01388116, -0.01738016,  0.0080645 ,\n",
       "           0.03544494, -0.00440388, -0.01931707, -0.05544048,\n",
       "          -0.08505561, -0.06224051,  0.0951192 , -0.04010644,\n",
       "           0.03478269, -0.01505451,  0.05155213, -0.00635932,\n",
       "          -0.1028052 ,  0.05245782, -0.05353372,  0.03395968,\n",
       "          -0.01261362,  0.0752767 , -0.04304256,  0.03826076,\n",
       "           0.03250607, -0.05311618, -0.06327093, -0.08855546,\n",
       "           0.04539523,  0.07003178,  0.05203553, -0.08953384],\n",
       "         [ 0.06853916, -0.01150896,  0.0637975 , -0.06606273,\n",
       "          -0.09095409,  0.07112472, -0.01247782,  0.09057669,\n",
       "          -0.05829418, -0.02114317,  0.0240695 , -0.04382025,\n",
       "           0.05956154, -0.09763564, -0.06821387,  0.04469205,\n",
       "           0.08959001,  0.03179723,  0.08722865,  0.09589982,\n",
       "           0.02213922, -0.07808536, -0.04785759,  0.09111064,\n",
       "           0.00676456, -0.0371073 , -0.0866376 ,  0.01182051,\n",
       "           0.01987509,  0.00951868,  0.10276966,  0.08982202]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_M_1.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
