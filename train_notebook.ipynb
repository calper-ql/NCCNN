{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dicts...\n",
      "Total time in fractional seconds: 24.546875\n"
     ]
    }
   ],
   "source": [
    "import scan_csv\n",
    "from LabelGenerator import *\n",
    "from client import OIDClient\n",
    "from FastSlidingWindow import *\n",
    "from Util import *\n",
    "\n",
    "ld = scan_csv.open_dicts()\n",
    "train_image_codec = ld['train codec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['class names', 'class encodings', 'train codec', 'train class', 'val codec', 'val class'])\n"
     ]
    }
   ],
   "source": [
    "print(ld.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "040c0777eb33f432\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "car_images = ld['train class'][ld['class encodings']['Car']][100:110]\n",
    "print(car_images[0])\n",
    "print(len(car_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "tf.Session(config=config).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(Y_pred, Y):\n",
    "    zeros = np.zeros([Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1], dtype=np.float32)\n",
    "    y2 = tf.reshape(Y_pred[:, :, :, 2], [Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1])\n",
    "    y4 = tf.reshape(Y_pred[:, :, :, 4], [Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1])\n",
    "    pred_x_w = tf.where(y2 > 0.0, y2, zeros) \n",
    "    pred_x_h = tf.where(y4 > 0.0, y4, zeros) \n",
    "    \n",
    "    x1_t = Y_pred[:, :, :, 1:2] - Y[:, :, :, 2:3] / 2.0\n",
    "    x2_t = Y_pred[:, :, :, 1:2] + Y[:, :, :, 2:3] / 2.0\n",
    "    \n",
    "    y1_t = Y_pred[:, :, :, 3:4] - Y[:, :, :, 4:5] / 2.0\n",
    "    y2_t = Y_pred[:, :, :, 3:4] + Y[:, :, :, 4:5] / 2.0\n",
    "    \n",
    "    x1_p = Y_pred[:, :, :, 1:2] - pred_x_w / 2.0\n",
    "    x2_p = Y_pred[:, :, :, 1:2] + pred_x_w / 2.0\n",
    "    \n",
    "    y1_p = Y_pred[:, :, :, 3:4] - pred_x_h / 2.0\n",
    "    y2_p = Y_pred[:, :, :, 3:4] + pred_x_h / 2.0\n",
    "    \n",
    "    cond1 = x2_t < x1_p\n",
    "    cond2 = x2_p < x1_t\n",
    "    cond3 = y2_t < y1_p\n",
    "    cond4 = y2_p < y1_t\n",
    "    cond_all = tf.logical_or(tf.logical_or(tf.logical_or(cond1, cond2), cond3), cond4)\n",
    "    \n",
    "    ious_np = np.zeros([Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1], dtype=np.float32)\n",
    "    \n",
    "    '''\n",
    "    far_x = np.min([x2_t, x2_p])\n",
    "    near_x = np.max([x1_t, x1_p])\n",
    "    far_y = np.min([y2_t, y2_p])\n",
    "    near_y = np.max([y1_t, y1_p])\n",
    "    '''\n",
    "    \n",
    "    far_x = tf.where(x2_t < x2_p, x2_t, x2_p)\n",
    "    near_x = tf.where(x1_t > x1_p, x1_t, x1_p)\n",
    "    far_y = tf.where(y2_t < y2_p, y2_t, y2_p)\n",
    "    near_y = tf.where(y1_t > y1_p, y1_t, y1_p)\n",
    "    \n",
    "    inter_area = (far_x - near_x + 1.0) * (far_y - near_y + 1.0)\n",
    "    true_box_area = (x2_t - x1_t + 1.0) * (y2_t - y1_t + 1.0)\n",
    "    pred_box_area = (x2_p - x1_p + 1.0) * (y2_p - y1_p + 1.0)\n",
    "    iou = inter_area / (true_box_area + pred_box_area - inter_area)\n",
    "    iou = tf.where(cond_all, ious_np, iou)\n",
    "    return iou\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread, Lock\n",
    "\n",
    "class Gatherer(threading.Thread):\n",
    "    def __init__(self, instances, ld, client, stride, size, overlap_ratio):\n",
    "        self.instances = instances\n",
    "        self.ld = ld\n",
    "        self.client = client\n",
    "        self.stride = stride\n",
    "        self.size = size\n",
    "        self.overlap_ratio = overlap_ratio\n",
    "        threading.Thread.__init__(self)\n",
    "        self.lock = Lock()\n",
    "        self.items = []\n",
    "        self.alive = True\n",
    "    \n",
    "    def run(self):\n",
    "        index = 0\n",
    "        while self.alive:\n",
    "            instance = self.instances[index]\n",
    "            index += 1\n",
    "            if index >= len(self.instances):\n",
    "                index = 0\n",
    "            self.lock.acquire()\n",
    "            if len(self.items) < 5:\n",
    "                X, Y, image, cmap = label_image(instance, \n",
    "                                     self.ld['train codec'], \n",
    "                                     self.ld['class names'], \n",
    "                                     self.client, self.stride, self.size, self.overlap_ratio)\n",
    "                self.items.append([X, Y, image, cmap])\n",
    "            self.lock.release()\n",
    "            \n",
    "    def get_next(self):\n",
    "        self.lock.acquire()\n",
    "        items = [None, None, None, None]\n",
    "        if len(self.items) > 0:\n",
    "            items = self.items[0]\n",
    "            self.items = self.items[1:]\n",
    "        self.lock.release()\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_val = 0.01\n",
    "W_M_1 = tf.Variable(np.random.uniform(-w_val, w_val, [4, 4, 3, 32]), dtype=tf.float32, name='WM1')\n",
    "W_M_1_1 = tf.Variable(np.random.uniform(-w_val, w_val, [4, 4, 32, 64]), dtype=tf.float32, name='WM1')\n",
    "W_M_2 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 64, 128]), dtype=tf.float32, name='WM2')\n",
    "W_M_2_2 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 128, 64]), dtype=tf.float32, name='WM2')\n",
    "W_M_3 = tf.Variable(np.random.uniform(-w_val, w_val, [7*7*64, 500]), dtype=tf.float32, name='WM3')\n",
    "W_M_4_F = tf.Variable(np.random.uniform(-w_val, w_val, [500, 1*5]), dtype=tf.float32, name='WM4F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started client thread\n",
      "0.9940811693668365\n",
      "0.4548831582069397\n",
      "0.9939253628253937\n",
      "0.9863222539424896\n",
      "0.9314422607421875\n",
      "0.38616421818733215\n",
      "0.3148595094680786\n",
      "0.9652137160301208\n",
      "0.6072561740875244\n",
      "0.7276712357997894\n",
      "0.7710805833339691\n",
      "0.7762318849563599\n",
      "0.3267209231853485\n",
      "0.32151129841804504\n",
      "0.622232973575592\n",
      "0.6936630308628082\n",
      "0.6406528949737549\n",
      "0.5690055042505264\n",
      "0.3722606897354126\n",
      "0.6365240663290024\n",
      "0.5311023443937302\n",
      "0.9963875412940979\n",
      "0.25592517852783203\n",
      "0.23690806329250336\n",
      "0.7663397490978241\n",
      "0.21451298892498016\n",
      "0.5857267677783966\n",
      "0.3700622618198395\n",
      "0.5050892233848572\n",
      "0.6297265589237213\n",
      "0.6000553965568542\n",
      "0.6073879301548004\n",
      "0.2493741810321808\n",
      "0.24689097702503204\n",
      "0.24917952716350555\n",
      "0.8274091184139252\n",
      "0.5741590708494186\n",
      "0.23457828164100647\n",
      "0.231856569647789\n",
      "0.5497265756130219\n",
      "0.448366641998291\n",
      "0.5244719237089157\n",
      "0.5517650693655014\n",
      "0.7732511907815933\n",
      "0.55660180747509\n",
      "0.5437265783548355\n",
      "0.5461185425519943\n",
      "0.544670581817627\n",
      "0.22475257515907288\n",
      "0.5341722965240479\n",
      "0.4411500245332718\n",
      "0.5462316274642944\n",
      "0.8671083897352219\n",
      "0.5428789258003235\n",
      "0.4652775973081589\n",
      "0.24465224146842957\n",
      "0.46820035576820374\n",
      "0.869437113404274\n",
      "0.5531294494867325\n",
      "0.5478719919919968\n",
      "0.5449024140834808\n",
      "0.5417308360338211\n",
      "0.5352304875850677\n",
      "0.22591237723827362\n",
      "0.44188642501831055\n",
      "0.525648295879364\n",
      "0.5421485006809235\n",
      "0.22223031520843506\n",
      "0.22304491698741913\n",
      "0.7613987922668457\n",
      "0.5397228002548218\n",
      "0.5479691922664642\n",
      "0.541001558303833\n",
      "0.5383837074041367\n",
      "0.5361447632312775\n",
      "0.5308013409376144\n",
      "0.22178664803504944\n",
      "0.22063806653022766\n",
      "0.5187872052192688\n",
      "0.5227449387311935\n",
      "0.5184314996004105\n",
      "0.5285933315753937\n",
      "0.5339448004961014\n",
      "0.535103514790535\n",
      "0.5344204008579254\n",
      "0.46223874390125275\n",
      "0.5339409559965134\n",
      "0.5349438637495041\n",
      "0.533249244093895\n",
      "0.22468386590480804\n",
      "0.5311546176671982\n",
      "0.5289459973573685\n",
      "0.5275498181581497\n",
      "0.7594775706529617\n",
      "0.22111132740974426\n",
      "0.7408485859632492\n",
      "0.21909810602664948\n",
      "0.43781788647174835\n",
      "0.21870726346969604\n",
      "0.22045095264911652\n",
      "0.5312972515821457\n",
      "0.22408998012542725\n",
      "0.22512413561344147\n",
      "0.44789642095565796\n",
      "0.5326793044805527\n",
      "0.22647538781166077\n",
      "0.5344135612249374\n",
      "0.7595179826021194\n",
      "0.5305965691804886\n",
      "0.22326231002807617\n",
      "0.5245043188333511\n",
      "0.22753490507602692\n",
      "0.5201536566019058\n",
      "0.7401397079229355\n",
      "0.5310263484716415\n",
      "0.4410400539636612\n",
      "0.5254644602537155\n",
      "0.5272464901208878\n",
      "0.8313614577054977\n",
      "0.528591588139534\n",
      "0.22353503108024597\n",
      "0.5268971920013428\n",
      "0.527008593082428\n",
      "0.5254393219947815\n",
      "0.22234497964382172\n",
      "0.5228674709796906\n",
      "0.520478367805481\n",
      "0.5243263840675354\n",
      "0.5172407627105713\n",
      "0.5183446705341339\n",
      "0.5242232233285904\n",
      "0.7435629814863205\n",
      "0.22285586595535278\n",
      "0.5273837894201279\n",
      "0.44975633919239044\n",
      "0.8320876657962799\n",
      "0.5258807837963104\n",
      "0.2228328436613083\n",
      "0.5265068262815475\n",
      "0.5202310681343079\n",
      "0.5195696502923965\n",
      "0.5190170854330063\n",
      "0.5239143669605255\n",
      "0.22069425880908966\n",
      "0.2206910401582718\n",
      "0.5217046439647675\n",
      "0.4412868320941925\n",
      "0.8211033344268799\n",
      "0.5191883593797684\n",
      "0.5181678682565689\n",
      "0.5167223662137985\n",
      "0.5183133780956268\n",
      "0.5191715359687805\n",
      "0.5246096700429916\n",
      "0.4442281723022461\n",
      "0.22143030166625977\n",
      "0.7466064840555191\n",
      "0.5214078724384308\n",
      "0.5220909714698792\n",
      "0.21978315711021423\n",
      "0.5189978182315826\n",
      "0.7298516631126404\n",
      "0.5151149332523346\n",
      "0.5125081390142441\n",
      "0.5192002952098846\n",
      "0.2201012372970581\n",
      "0.22104880213737488\n",
      "0.5248742550611496\n",
      "0.5239850431680679\n",
      "0.5260280966758728\n",
      "0.5250585526227951\n",
      "0.5217508971691132\n",
      "0.4418603926897049\n",
      "0.21863529086112976\n",
      "0.5191808938980103\n",
      "0.21645702421665192\n",
      "0.5110317021608353\n",
      "0.21592354774475098\n",
      "0.429073229432106\n",
      "0.5178775489330292\n",
      "0.8242037892341614\n",
      "0.2271837294101715\n",
      "0.456958532333374\n",
      "0.5408943295478821\n",
      "0.5456295609474182\n",
      "0.5390786081552505\n",
      "0.537325069308281\n",
      "0.5379720628261566\n",
      "0.5353768616914749\n",
      "0.5303303301334381\n",
      "0.5283337235450745\n",
      "0.2217903435230255\n",
      "0.5226793885231018\n",
      "0.21893438696861267\n",
      "0.5161512494087219\n",
      "0.21697962284088135\n",
      "0.5113866478204727\n",
      "0.5089568048715591\n",
      "0.43424831330776215\n",
      "0.8141412883996964\n",
      "0.22271835803985596\n",
      "1.0524572283029556\n",
      "0.5259720087051392\n",
      "0.22267639636993408\n",
      "0.5273697674274445\n",
      "0.5221095085144043\n",
      "0.5223497599363327\n",
      "0.218997061252594\n",
      "0.5199268460273743\n",
      "0.5148183107376099\n",
      "0.7296473383903503\n",
      "0.509156197309494\n",
      "0.5131154656410217\n",
      "0.5115598291158676\n",
      "0.5188335031270981\n",
      "0.750690683722496\n",
      "0.53974948823452\n",
      "0.22639620304107666\n",
      "0.5387816429138184\n",
      "0.7602535784244537\n",
      "0.531797468662262\n",
      "0.5328463912010193\n",
      "0.2243998497724533\n",
      "0.5301672965288162\n",
      "0.5249687284231186\n",
      "0.22348028421401978\n",
      "0.5246177911758423\n",
      "0.5193128734827042\n",
      "0.2193838357925415\n",
      "0.7322770357131958\n",
      "0.0\n",
      "0.5110900551080704\n",
      "0.4273284077644348\n",
      "0.21298091113567352\n",
      "0.21723727881908417\n",
      "0.5185118168592453\n",
      "0.43553130328655243\n",
      "0.5221557170152664\n",
      "0.5240765810012817\n",
      "0.5266415029764175\n",
      "0.5282370001077652\n",
      "0.5256285667419434\n",
      "0.5270875841379166\n",
      "0.22168202698230743\n",
      "0.22136545181274414\n",
      "0.524906724691391\n",
      "0.4424271434545517\n",
      "0.21963979303836823\n",
      "0.5218096226453781\n",
      "0.7345210909843445\n",
      "0.5152180790901184\n",
      "0.51247139275074\n",
      "0.21459154784679413\n",
      "0.5085534900426865\n",
      "0.2133593112230301\n",
      "0.7243341952562332\n",
      "0.5183735340833664\n",
      "0.5260320603847504\n",
      "0.5354829132556915\n",
      "0.5326901972293854\n",
      "0.5394587963819504\n",
      "0.5402350425720215\n",
      "0.848593145608902\n",
      "0.5373297780752182\n",
      "0.5320648401975632\n",
      "0.5334124267101288\n",
      "0.5304976999759674\n",
      "0.22208017110824585\n",
      "0.525518387556076\n",
      "0.22133071720600128\n",
      "0.7421047985553741\n",
      "0.518210232257843\n",
      "0.5152096450328827\n",
      "0.43397483229637146\n",
      "0.8063451498746872\n",
      "0.5083979219198227\n",
      "0.506662517786026\n",
      "0.5069651156663895\n",
      "0.5134693384170532\n",
      "0.517889142036438\n",
      "0.5185934454202652\n",
      "0.5198647528886795\n",
      "0.2244855761528015\n",
      "0.5247455835342407\n",
      "0.44287876784801483\n",
      "0.8247580379247665\n",
      "0.5228502154350281\n",
      "0.2205192744731903\n",
      "0.520281121134758\n",
      "0.2184630185365677\n",
      "0.21787947416305542\n",
      "0.21725457906723022\n",
      "0.5142668038606644\n",
      "0.5128272026777267\n",
      "0.5115479975938797\n",
      "0.42979957163333893\n",
      "0.5080312490463257\n",
      "0.5067424476146698\n",
      "0.505518913269043\n",
      "0.2171086072921753\n",
      "0.5103576630353928\n",
      "0.5175289660692215\n",
      "0.7372927516698837\n",
      "0.5232071727514267\n",
      "0.525425374507904\n",
      "0.7425509542226791\n",
      "0.5216008722782135\n",
      "0.5221611708402634\n",
      "0.5200443714857101\n",
      "0.5172151178121567\n",
      "0.5154179334640503\n",
      "0.5139955431222916\n",
      "0.5120014995336533\n",
      "0.5101038664579391\n",
      "0.5085193067789078\n",
      "0.5071232616901398\n",
      "0.505909651517868\n",
      "0.5091533660888672\n",
      "0.5161250978708267\n",
      "0.7321882992982864\n",
      "0.5181657373905182\n",
      "0.5199592411518097\n",
      "0.5199272036552429\n",
      "0.21931801736354828\n",
      "0.5207523703575134\n",
      "0.43843939900398254\n",
      "0.5193089991807938\n",
      "0.21860426664352417\n",
      "0.5180034637451172\n",
      "0.5163518488407135\n",
      "0.7305551320314407\n",
      "0.5124184936285019\n",
      "0.5110206454992294\n",
      "0.5095578879117966\n",
      "0.7218540757894516\n",
      "0.506511777639389\n",
      "0.21295246481895447\n",
      "0.5088238716125488\n",
      "0.512984573841095\n",
      "0.5119582414627075\n",
      "0.5144506841897964\n",
      "0.435866117477417\n",
      "0.5183499604463577\n",
      "0.5200363546609879\n",
      "0.5205892622470856\n",
      "0.5198994576931\n",
      "0.5196840018033981\n",
      "0.5193227529525757\n",
      "0.21866285800933838\n",
      "0.517544224858284\n",
      "0.5162093937397003\n",
      "0.5142955183982849\n",
      "0.21683058142662048\n",
      "0.7283588200807571\n",
      "0.510380208492279\n",
      "0.5091917365789413\n",
      "0.508026510477066\n",
      "0.21353159844875336\n",
      "0.5077138543128967\n",
      "0.5072757750749588\n",
      "0.726846307516098\n",
      "0.5121236592531204\n",
      "0.5133084952831268\n",
      "0.5153587460517883\n",
      "0.21839956939220428\n",
      "1.0349976569414139\n",
      "0.5174204111099243\n",
      "0.5165209770202637\n",
      "0.0\n",
      "0.21829508244991302\n",
      "0.5160235613584518\n",
      "0.5148945748806\n",
      "0.7297893166542053\n",
      "0.5118560343980789\n",
      "0.5106485337018967\n",
      "0.5096616446971893\n",
      "0.508616104722023\n",
      "0.5075350552797318\n",
      "0.42674919962882996\n",
      "0.5086165964603424\n",
      "0.507899284362793\n",
      "0.5110949128866196\n",
      "0.5155716240406036\n",
      "0.5121249258518219\n",
      "0.21685481071472168\n",
      "0.43461038172245026\n",
      "0.5149762779474258\n",
      "0.5160238295793533\n",
      "0.5156549215316772\n",
      "0.21702663600444794\n",
      "0.21701252460479736\n",
      "0.6500438004732132\n",
      "0.5143036395311356\n"
     ]
    }
   ],
   "source": [
    "client = OIDClient('192.168.1.31', 33333)\n",
    "loss_value = tf.Variable(0.0, dtype=tf.float32)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "gatherer = Gatherer(car_images, ld, client, 30, 50, 0.1)\n",
    "gatherer.start()\n",
    "\n",
    "def mean_squared(inputs, targets):\n",
    "  error = inputs - targets\n",
    "  return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "index = 0\n",
    "loss = 0.0\n",
    "while True:\n",
    "    items = gatherer.get_next()\n",
    "    X, Y, image, cmap = items[0], items[1], items[2], items[3]\n",
    "    \n",
    "    \n",
    "    #X, Y, image, cmap = label_image(instance, train_image_codec, ld['class names'], client, 30, 50)\n",
    "    #X, Y, image, cmap = gather(car_images, ld, client, 30, 50)\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    if image is not None:\n",
    "        if np.max([image.shape[0], image.shape[1]]) >= 2000:\n",
    "            image = None\n",
    "\n",
    "    if image is not None:\n",
    "        # ONLY CAR\n",
    "        Y = Y[:, :, 570:571, :]\n",
    "\n",
    "        iou_sum = 0.0\n",
    "        iou_mean = 0.0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # ENCODE\n",
    "            X_flat = tf.reshape(X, [X.shape[0]*X.shape[1], X.shape[2], X.shape[3], X.shape[4]])\n",
    "            encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(X_flat, W_M_1, [1, 2, 2, 1], 'SAME'))\n",
    "            encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(encode_conv, W_M_1_1, [1, 2, 2, 1], 'SAME'))\n",
    "            share_conv = encode_conv\n",
    "\n",
    "            share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2, [1, 1, 1, 1], 'SAME'))\n",
    "            share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_2, [1, 2, 2, 1], 'SAME'))\n",
    "            share_flat = tf.reshape(share_conv, [share_conv.shape[0], W_M_3.shape[0]])\n",
    "\n",
    "            flat_1 = tf.nn.leaky_relu(tf.matmul(share_flat, W_M_3))\n",
    "            Y_pred = tf.matmul(flat_1, W_M_4_F)\n",
    "            class_pred = tf.nn.sigmoid(Y_pred[:, 0])\n",
    "            Y_pred = tf.stack([class_pred, Y_pred[:, 1], Y_pred[:, 2], Y_pred[:, 3], \n",
    "                               Y_pred[:, 4]], axis=1)\n",
    "            Y_pred = tf.reshape(Y_pred, Y.shape)\n",
    "\n",
    "\n",
    "            iou = calc_iou(Y_pred, Y)\n",
    "            iou_1 = 1.0 - tf.reduce_mean(iou)\n",
    "\n",
    "            ms = mean_squared(Y_pred, Y)\n",
    "            loss_value = ms + iou_1\n",
    "\n",
    "        loss += loss_value.numpy()\n",
    "        params = [W_M_1, W_M_1_1, W_M_2, W_M_2_2, W_M_3, W_M_4_F]\n",
    "        optimizer.apply_gradients(zip(tape.gradient(loss_value, params), params),\n",
    "                            global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "        img_orig = draw_from_label(image, Y, cmap, 50, 0.0, True)\n",
    "        img_pred = draw_from_label(image, Y_pred.numpy(), cmap, 50, 0.9, True)\n",
    "\n",
    "        #print(Y_pred.numpy()[5, 5])\n",
    "        cv2.imshow('orig', img_orig)\n",
    "        cv2.imshow('pred', img_pred)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            gatherer.alive = False\n",
    "            break\n",
    "    index += 1\n",
    "    if index >= len(car_images):\n",
    "        index = 0\n",
    "        print(loss)\n",
    "        loss = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
