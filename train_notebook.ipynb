{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scan_csv\n",
    "from FastSlidingWindow import *\n",
    "from Util import *\n",
    "from bbd100k_loader import *\n",
    "from scan_csv import progress\n",
    "\n",
    "loader = BBD100K_Loader(True)\n",
    "color_map = generate_color_from_categories(loader.category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "tf.Session(config=config).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(Y_pred, Y):\n",
    "    #print(Y_pred.shape)\n",
    "    zeros = np.zeros([Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1], dtype=np.float32)\n",
    "    y2 = tf.reshape(Y_pred[:, :, :, 2], [Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1])\n",
    "    y4 = tf.reshape(Y_pred[:, :, :, 4], [Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1])\n",
    "    pred_x_w = tf.where(y2 > 0.0, y2, zeros) \n",
    "    pred_x_h = tf.where(y4 > 0.0, y4, zeros) \n",
    "    \n",
    "    x1_t = Y_pred[:, :, :, 1:2] - Y[:, :, :, 2:3] / 2.0\n",
    "    x2_t = Y_pred[:, :, :, 1:2] + Y[:, :, :, 2:3] / 2.0\n",
    "    \n",
    "    y1_t = Y_pred[:, :, :, 3:4] - Y[:, :, :, 4:5] / 2.0\n",
    "    y2_t = Y_pred[:, :, :, 3:4] + Y[:, :, :, 4:5] / 2.0\n",
    "    \n",
    "    x1_p = Y_pred[:, :, :, 1:2] - pred_x_w / 2.0\n",
    "    x2_p = Y_pred[:, :, :, 1:2] + pred_x_w / 2.0\n",
    "    \n",
    "    y1_p = Y_pred[:, :, :, 3:4] - pred_x_h / 2.0\n",
    "    y2_p = Y_pred[:, :, :, 3:4] + pred_x_h / 2.0\n",
    "    \n",
    "    cond1 = x2_t < x1_p\n",
    "    cond2 = x2_p < x1_t\n",
    "    cond3 = y2_t < y1_p\n",
    "    cond4 = y2_p < y1_t\n",
    "    cond_all = tf.logical_or(tf.logical_or(tf.logical_or(cond1, cond2), cond3), cond4)\n",
    "    \n",
    "    ious_np = np.zeros([Y_pred.shape[0], Y_pred.shape[1], Y_pred.shape[2], 1], dtype=np.float32)\n",
    "    \n",
    "    far_x = tf.where(x2_t < x2_p, x2_t, x2_p)\n",
    "    near_x = tf.where(x1_t > x1_p, x1_t, x1_p)\n",
    "    far_y = tf.where(y2_t < y2_p, y2_t, y2_p)\n",
    "    near_y = tf.where(y1_t > y1_p, y1_t, y1_p)\n",
    "    \n",
    "    inter_area = (far_x - near_x + 1.0) * (far_y - near_y + 1.0)\n",
    "    true_box_area = (x2_t - x1_t + 1.0) * (y2_t - y1_t + 1.0)\n",
    "    pred_box_area = (x2_p - x1_p + 1.0) * (y2_p - y1_p + 1.0)\n",
    "    iou = inter_area / (true_box_area + pred_box_area - inter_area)\n",
    "    iou = tf.where(cond_all, ious_np, iou)\n",
    "    return iou\n",
    "    \n",
    "#iou_1 = calc_iou(Y_pred, Y)\n",
    "#iou = 1.0 - tf.reduce_mean(iou_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_val = 0.1\n",
    "W_M_1 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 3, 32]), dtype=tf.float32, name='WM1')\n",
    "W_M_1_1 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 32, 64]), dtype=tf.float32, name='WM11')\n",
    "W_M_2 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 64, 128]), dtype=tf.float32, name='WM2')\n",
    "W_M_2_1 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 128, 256]), dtype=tf.float32, name='WM21')\n",
    "W_M_2_2 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 256, 256]), dtype=tf.float32, name='WM22')\n",
    "W_M_2_3 = tf.Variable(np.random.uniform(-w_val, w_val, [3, 3, 256, 512]), dtype=tf.float32, name='WM23')\n",
    "W_M_2_4 = tf.Variable(np.random.uniform(-w_val, w_val, [2, 2, 512, 256]), dtype=tf.float32, name='WM24')\n",
    "W_M_3 = tf.Variable(np.random.uniform(-w_val, w_val, [2*2*256, 256]), dtype=tf.float32, name='WM3')\n",
    "W_M_3_1 = tf.Variable(np.random.uniform(-w_val, w_val, [256, 128]), dtype=tf.float32, name='WM31')\n",
    "\n",
    "W_M_C = tf.Variable(np.random.uniform(-w_val, w_val, [128*5, 128]), dtype=tf.float32, name='WMC')\n",
    "\n",
    "W_M_4_F = tf.Variable(np.random.uniform(-w_val, w_val, [128, len(loader.category_dict)*5]), \n",
    "                      dtype=tf.float32, name='WM4F')\n",
    "\n",
    "params = [W_M_1, W_M_1_1, W_M_2, W_M_2_1, W_M_2_2, W_M_2_3, \n",
    "          W_M_2_4, W_M_3, W_M_3_1, W_M_4_F, W_M_C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 must be added for shifted\n",
    "def index_lookup_generator(w, h):\n",
    "    indices = np.zeros([w, h, 5, 2], dtype=np.int32)\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            l = [[i, j-1], [i, j+1], [i, j], [i-1, j], [i+1, j]]\n",
    "            indices[i, j] = l\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(params, extention=''):\n",
    "    for p in params:\n",
    "        np.save(\"weights/\"+p.name.replace(':', '_')+'_'+extention, p.numpy())\n",
    "        \n",
    "def load_weights(params, extention=''):\n",
    "    for p in params:\n",
    "        p.assign(np.load(\"weights/\"+p.name.replace(':', '_')+'_'+extention+'.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X):\n",
    "    X_flat = tf.reshape(X, [X.shape[0]*X.shape[1], X.shape[2], X.shape[3], X.shape[4]])\n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(X_flat, W_M_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(encode_conv, W_M_1_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = encode_conv\n",
    "\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_3, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_4, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    #print(share_conv.shape)\n",
    "    \n",
    "    share_flat = tf.reshape(share_conv, [share_conv.shape[0], W_M_3.shape[0]])\n",
    "    flat_1 = tf.nn.leaky_relu(tf.matmul(share_flat, W_M_3), alpha=0.1)\n",
    "    flat_2 = tf.nn.leaky_relu(tf.matmul(flat_1, W_M_3_1), alpha=0.1)\n",
    "        \n",
    "    flat_2 = tf.reshape(flat_2, [X.shape[0], X.shape[1], flat_2.shape[1]])\n",
    "    padded = tf.pad(flat_2, [[1, 1], [1, 1], [0, 0]])\n",
    "    indices = index_lookup_generator(X.shape[0], X.shape[1]) + 1\n",
    "    collaborations = tf.gather_nd(padded, indices)\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "    final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    for i in range(2):\n",
    "        final = tf.reshape(final, [X.shape[0], X.shape[1], final.shape[1]])\n",
    "        padded = tf.pad(final, [[1, 1], [1, 1], [0, 0]])\n",
    "        collaborations = tf.gather_nd(padded, indices)\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "        final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    Y_pred = tf.matmul(final, W_M_4_F)\n",
    "    Y_pred = tf.reshape(Y_pred, [Y_pred.shape[0], len(loader.category_dict), 5])\n",
    "    Y_pred = tf.reshape(Y_pred, Y.shape)\n",
    "    \n",
    "    class_pred = tf.nn.sigmoid(Y_pred[:, :, :, 0])\n",
    "    xc_pred = Y_pred[:, :, :, 1]\n",
    "    yc_pred = Y_pred[:, :, :, 3]\n",
    "    xw_pred = tf.square(Y_pred[:, :, :, 2])\n",
    "    yw_pred = tf.square(Y_pred[:, :, :, 4])\n",
    "    \n",
    "    #Y_pred = tf.nn.leaky_relu(Y_pred, alpha=0.5)\n",
    "    Y_pred = tf.stack([class_pred, \n",
    "                       xc_pred, \n",
    "                       xw_pred, \n",
    "                       yc_pred, \n",
    "                       yw_pred], axis=3)\n",
    "\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared(inputs, targets):\n",
    "    error = tf.to_double(inputs) - tf.to_double(targets)\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def bbox_loss(Y_pred, Y):\n",
    "    ms = tf.square(1.0 + mean_squared(Y_pred[:, :, 0], Y[:, :, 0]))\n",
    "    xm = tf.square(1.0 + mean_squared(Y_pred[:, :, 1], Y[:, :, 1]))\n",
    "    ym = tf.square(1.0 + mean_squared(Y_pred[:, :, 3], Y[:, :, 3]))\n",
    "    xwm = mean_squared(Y_pred[:, :, 2], Y[:, :, 2])\n",
    "    ywm = mean_squared(Y_pred[:, :, 4], Y[:, :, 4])\n",
    "    return ms+xm+ym+xwm+ywm\n",
    "\n",
    "def back_prop(X, Y):\n",
    "    #y_m = np.mean(Y[:, :, :, 0], axis=2) >= 0.0\n",
    "    #Y_true = Y[y_m]\n",
    "    #X_flat = X[y_m]\n",
    "    Y_true = tf.reshape(Y, [Y.shape[0]*Y.shape[1], Y.shape[2], Y.shape[3]])\n",
    "    X_flat = tf.reshape(X, [X.shape[0]*X.shape[1], X.shape[2], X.shape[3], X.shape[4]])\n",
    "    \n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(X_flat, W_M_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    encode_conv = tf.nn.leaky_relu(tf.nn.conv2d(encode_conv, W_M_1_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = encode_conv\n",
    "\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_1, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_2, [1, 2, 2, 1], 'SAME'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_3, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    share_conv = tf.nn.leaky_relu(tf.nn.conv2d(share_conv, W_M_2_4, [1, 1, 1, 1], 'VALID'), alpha=0.1)\n",
    "    #print(share_conv.shape)\n",
    "    \n",
    "    share_flat = tf.reshape(share_conv, [share_conv.shape[0], W_M_3.shape[0]])\n",
    "    flat_1 = tf.nn.leaky_relu(tf.matmul(share_flat, W_M_3), alpha=0.1)\n",
    "    flat_2 = tf.nn.leaky_relu(tf.matmul(flat_1, W_M_3_1), alpha=0.1)\n",
    "        \n",
    "    flat_2 = tf.reshape(flat_2, [X.shape[0], X.shape[1], flat_2.shape[1]])\n",
    "    padded = tf.pad(flat_2, [[1, 1], [1, 1], [0, 0]])\n",
    "    indices = index_lookup_generator(X.shape[0], X.shape[1]) + 1\n",
    "    collaborations = tf.gather_nd(padded, indices)\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "    collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "    final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    for i in range(2):\n",
    "        final = tf.reshape(final, [X.shape[0], X.shape[1], final.shape[1]])\n",
    "        padded = tf.pad(final, [[1, 1], [1, 1], [0, 0]])\n",
    "        collaborations = tf.gather_nd(padded, indices)\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0], X.shape[1], collaborations.shape[-1]*5])\n",
    "        collaborations = tf.reshape(collaborations, [X.shape[0] * X.shape[1], collaborations.shape[-1]])\n",
    "        final =  tf.nn.leaky_relu(tf.matmul(collaborations, W_M_C), alpha=0.1)\n",
    "    \n",
    "    Y_pred = tf.matmul(final, W_M_4_F)\n",
    "    Y_pred = tf.reshape(Y_pred, [Y_pred.shape[0], len(loader.category_dict), 5])\n",
    "    \n",
    "    class_pred = tf.nn.sigmoid(Y_pred[:, :, 0])\n",
    "    xc_pred = Y_pred[:, :, 1]\n",
    "    yc_pred = Y_pred[:, :, 3]\n",
    "    xw_pred = tf.square(Y_pred[:, :, 2])\n",
    "    yw_pred = tf.square(Y_pred[:, :, 4])\n",
    "    \n",
    "    #Y_pred = tf.nn.leaky_relu(Y_pred, alpha=0.5)\n",
    "    Y_pred = tf.stack([class_pred, \n",
    "                       xc_pred, \n",
    "                       xw_pred, \n",
    "                       yc_pred, \n",
    "                       yw_pred], axis=2)\n",
    "    \n",
    "    loss_value = bbox_loss(Y_pred, Y_true)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "loss_values = []\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_list = []\n",
    "loss_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[----------------------------------------] 0.6% -> 428\r"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "def plot_loss(losses):\n",
    "    losses_np = np.array(losses)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(losses_np, label='loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "patch_size = 150\n",
    "stride = 50\n",
    "\n",
    "loss = 0.0\n",
    "\n",
    "while True:\n",
    "    X, Y, image, cmap = loader.gather(index, stride, patch_size, 0.1)\n",
    "    \n",
    "    if image is not None:\n",
    "        if np.max([image.shape[0], image.shape[1]]) >= 2000:\n",
    "            image = None\n",
    "\n",
    "    if image is not None:\n",
    "        iou_sum = 0.0\n",
    "        iou_mean = 0.0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = back_prop(X, Y)\n",
    "\n",
    "        loss += loss_value.numpy()\n",
    "        if loss_value.numpy() < 0.0:\n",
    "            print('dun goofd')\n",
    "            break\n",
    "            \n",
    "        grads_and_vars = tape.gradient(loss_value, params)\n",
    "        capped_grads_and_vars = [tf.clip_by_value(gv, -5., 5.) for gv in grads_and_vars]\n",
    "        optimizer.apply_gradients(zip(capped_grads_and_vars, params), \n",
    "                                              global_step=tf.train.get_or_create_global_step()) \n",
    "        \n",
    "        Y_pred = feed_forward(X)\n",
    "        #Y_pred_list.append(Y_pred)\n",
    "        img_orig = draw_from_label(image, Y, cmap, patch_size, color_map, 0.1, draw_patches=False, \n",
    "                                   max_count=1000)\n",
    "        img_pred = draw_from_label(image, Y_pred.numpy(), cmap, patch_size, color_map, 0.9, \n",
    "                                   max_count=100, draw_patches=False)\n",
    "\n",
    "        cv2.imshow('orig', img_orig)\n",
    "        cv2.imshow('pred', img_pred)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    progress(index, loader.image_count, index)\n",
    "    index += 1\n",
    "    if index % 100 == 0:\n",
    "        save_weights(params, extention='bckp')\n",
    "    if index >= loader.image_count:\n",
    "        index = 0\n",
    "        loss_values.append(loss)\n",
    "        plot_loss(loss_values)\n",
    "        print(' ' + str(loss))\n",
    "        loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights(params, 'bckp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, image, cmap = loader.gather(333, stride, patch_size, 0.1)\n",
    "X = np.array(X, dtype=np.float32)\n",
    "Y_pred = feed_forward(X)\n",
    "while(True):\n",
    "    img_orig = draw_from_label(image, Y, cmap, patch_size, color_map, 0.1, draw_patches=False, max_count=1000)\n",
    "    img_pred = draw_from_label(image, Y_pred.numpy(), cmap, patch_size, color_map, 0.0, draw_patches=True)\n",
    "    cv2.imshow('orig', img_orig)\n",
    "    cv2.imshow('pred', img_pred)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    X, Y, image, cmap = loader.gather(333, stride, patch_size, 0.1)\n",
    "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, 60.0, (image.shape[1], image.shape[0]))\n",
    "    last_Y_pred = None\n",
    "    for Y_pred in Y_pred_list:\n",
    "        img_pred = draw_from_label(image, Y_pred.numpy(), cmap, \n",
    "                                   patch_size, color_map, 0.1, draw_patches=False, max_count=10000)\n",
    "        out.write(img_pred)\n",
    "        last_Y_pred = Y_pred\n",
    "\n",
    "    for i in range(120):\n",
    "        img_pred = draw_from_label(image, last_Y_pred.numpy(), cmap, \n",
    "                                   patch_size, color_map, 0.5, draw_patches=False, max_count=10000)\n",
    "        out.write(img_pred)\n",
    "        \n",
    "    for i in range(120):\n",
    "        img_pred = draw_from_label(image, last_Y_pred.numpy(), cmap, \n",
    "                                   patch_size, color_map, 0.7, draw_patches=False, max_count=10000)\n",
    "        out.write(img_pred)\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "cap = cv2.VideoCapture('drive_footage.mp4')\n",
    "indices = None\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    X, cmap, indices = eager_sliding_window(frame, stride, patch_size, indices)\n",
    "    Y_pred = feed_forward(X)\n",
    "    drawn = draw_from_label(frame, Y_pred.numpy(), cmap, \n",
    "                                   patch_size, color_map, 0.9, draw_patches=False, max_count=10000)\n",
    "    cv2.imshow('frame', drawn)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_M_1.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
